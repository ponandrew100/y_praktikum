{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'train', 'test', 'sample_submission.csv', 'labels.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.listdir('../input/imet-2020-fgvc7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attribute_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00011f01965f141f5d1eea6592fa9862</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00014abc91ed3e4bf1663fde8136fe80</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002e2054e303badc1a33463f6fb7973</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002e8f35f85f28bebfb28f2a627dc4d</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00082dfc0de78506f96104bc05eb5a49</td>\n",
       "      <td>0 1 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id attribute_ids\n",
       "0  00011f01965f141f5d1eea6592fa9862         0 1 2\n",
       "1  00014abc91ed3e4bf1663fde8136fe80         0 1 2\n",
       "2  0002e2054e303badc1a33463f6fb7973         0 1 2\n",
       "3  0002e8f35f85f28bebfb28f2a627dc4d         0 1 2\n",
       "4  00082dfc0de78506f96104bc05eb5a49         0 1 2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../input/imet-2020-fgvc7/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as M\n",
    "from albumentations import Compose, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=777):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 3474\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, labels, transform=None):\n",
    "        self.df = df\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.df['id'].values[idx]\n",
    "        file_path = f'../input/imet-2020-fgvc7/train/{file_name}.png'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        label = self.labels.values[idx]\n",
    "        target = torch.zeros(N_CLASSES)\n",
    "        for cls in label.split():\n",
    "            target[int(cls)] = 1\n",
    "        \n",
    "        return image, target\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.df['id'].values[idx]\n",
    "        file_path = f'../input/imet-2020-fgvc7/test/{file_name}.png'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 128\n",
    "WIDTH = 128\n",
    "\n",
    "\n",
    "def get_transforms(data):\n",
    "    assert data in ('train', 'valid')\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            #Resize(HEIGHT, WIDTH),\n",
    "            RandomResizedCrop(HEIGHT, WIDTH),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            #Resize(HEIGHT, WIDTH),\n",
    "            RandomCrop(256, 256),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "            \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "test_dataset = TestDataset(submission, transform=get_transforms('valid'))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgPool(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x, x.shape[2:])\n",
    "\n",
    "\n",
    "def create_net(net_cls, pretrained: bool):\n",
    "    if pretrained:\n",
    "        net = net_cls()\n",
    "        model_name = net_cls.__name__\n",
    "        weights_path = f'../input/{model_name}/{model_name}.pth'\n",
    "        net.load_state_dict(torch.load(weights_path))\n",
    "    else:\n",
    "        net = net_cls(pretrained=pretrained)\n",
    "    return net\n",
    "\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=False, net_cls=M.resnet50):\n",
    "        super().__init__()\n",
    "        self.net = create_net(net_cls, pretrained=pretrained)\n",
    "        self.net.avgpool = AvgPool()\n",
    "        self.net.fc = torch.nn.Linear(self.net.fc.in_features, num_classes)\n",
    "\n",
    "    def fresh_params(self):\n",
    "        return self.net.fc.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "resnet50 = partial(ResNet, net_cls=M.resnet50)\n",
    "resnet101 = partial(ResNet, net_cls=M.resnet101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "model_101 = resnet101(num_classes=N_CLASSES, pretrained=True)\n",
    "model_fold0 = resnet50(num_classes=N_CLASSES, pretrained=True)\n",
    "model_fold1 = resnet50(num_classes=N_CLASSES, pretrained=True)\n",
    "model_fold2 = resnet50(num_classes=N_CLASSES, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path):\n",
    "    print(path)\n",
    "    state = torch.load(str(path))\n",
    "    state_model = state['model']\n",
    "    wrong_keys = {\n",
    "        'net.fc.1.weight': 'net.fc.weight', \n",
    "        'net.fc.1.bias': 'net.fc.bias'\n",
    "    }\n",
    "    state['model'] = OrderedDict((wrong_keys.get(k) if k in wrong_keys else k, v) \n",
    "                                 for k, v in state_model.items())\n",
    "    model.load_state_dict(state['model'])\n",
    "    print('Loaded model from epoch {epoch}, step {step:,}'.format(**state))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import time\n",
    "\n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n",
    "    \n",
    "    log_format = '%(asctime)s %(levelname)s %(message)s'\n",
    "    \n",
    "    stream_handler = StreamHandler()\n",
    "    stream_handler.setLevel(DEBUG)\n",
    "    stream_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    file_handler = FileHandler(log_file)\n",
    "    file_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    logger = getLogger('Herbarium')\n",
    "    logger.setLevel(DEBUG)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "LOG_FILE = 'train.log'\n",
    "LOGGER = init_logger(LOG_FILE)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/bestforresnet101/my-best-model2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 19:06:39,817 INFO [inference] start\n",
      "  0%|          | 0/203 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 19, step 31,986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [05:59<00:00,  1.77s/it]\n",
      "2020-05-14 19:12:39,486 INFO [inference] done in 360 s.\n"
     ]
    }
   ],
   "source": [
    "load_model(model_101, '../input/bestforresnet101/my-best-model2.pt')\n",
    "\n",
    "with timer('inference'):\n",
    "    model_101.to(device) \n",
    "    preds_model101 = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "    for i, images in tk0:\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model_101(images)\n",
    "        preds_model101.append(torch.sigmoid(y_preds).to('cpu').numpy())     \n",
    "    \n",
    "np_model101=np.concatenate(preds_model101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_fold0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/bestforresnet50/best-model0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 19:12:39,825 INFO [inference] start\n",
      "  0%|          | 0/203 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 20, step 33,763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [03:53<00:00,  1.15s/it]\n",
      "2020-05-14 19:16:33,657 INFO [inference] done in 234 s.\n"
     ]
    }
   ],
   "source": [
    "load_model(model_fold0, '../input/bestforresnet50/best-model0.pt')\n",
    "\n",
    "with timer('inference'):\n",
    "    model_fold0.to(device) \n",
    "    preds_model_fold0 = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "    for i, images in tk0:\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model_fold0(images)\n",
    "        preds_model_fold0.append(torch.sigmoid(y_preds).to('cpu').numpy())   \n",
    "    \n",
    "np_fold0=np.concatenate(preds_model_fold0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/bestforresnet50/best-model1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 19:16:34,074 INFO [inference] start\n",
      "  0%|          | 0/203 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 20, step 33,744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [03:51<00:00,  1.14s/it]\n",
      "2020-05-14 19:20:25,672 INFO [inference] done in 232 s.\n"
     ]
    }
   ],
   "source": [
    "load_model(model_fold1, '../input/bestforresnet50/best-model1.pt')\n",
    "\n",
    "with timer('inference'):\n",
    "    model_fold1.to(device) \n",
    "    preds_model_fold1 = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "    for i, images in tk0:\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model_fold1(images)\n",
    "        preds_model_fold1.append(torch.sigmoid(y_preds).to('cpu').numpy())      \n",
    "        \n",
    "np_fold1=np.concatenate(preds_model_fold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_fold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/bestforresnet50/best-model2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-14 19:20:26,066 INFO [inference] start\n",
      "  0%|          | 0/203 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 16, step 26,655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [03:50<00:00,  1.14s/it]\n",
      "2020-05-14 19:24:16,583 INFO [inference] done in 231 s.\n"
     ]
    }
   ],
   "source": [
    "load_model(model_fold2, '../input/bestforresnet50/best-model2.pt')\n",
    "\n",
    "with timer('inference'):\n",
    "    model_fold2.to(device) \n",
    "    preds_model_fold2 = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "    for i, images in tk0:\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model_fold2(images)\n",
    "        preds_model_fold2.append(torch.sigmoid(y_preds).to('cpu').numpy())      \n",
    "        \n",
    "np_fold2=np.concatenate(preds_model_fold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred = np.mean( np.array([np_model101, np_fold0, np_fold1, np_fold2]), axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attribute_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00011f01965f141f5d1eea6592fa9862</td>\n",
       "      <td>149 370 2493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00014abc91ed3e4bf1663fde8136fe80</td>\n",
       "      <td>233 783 2103 2436 3433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002e2054e303badc1a33463f6fb7973</td>\n",
       "      <td>149 370 2493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002e8f35f85f28bebfb28f2a627dc4d</td>\n",
       "      <td>784 1131 3170 3364 3392 3456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00082dfc0de78506f96104bc05eb5a49</td>\n",
       "      <td>641 784 2557 3334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                 attribute_ids\n",
       "0  00011f01965f141f5d1eea6592fa9862                  149 370 2493\n",
       "1  00014abc91ed3e4bf1663fde8136fe80        233 783 2103 2436 3433\n",
       "2  0002e2054e303badc1a33463f6fb7973                  149 370 2493\n",
       "3  0002e8f35f85f28bebfb28f2a627dc4d  784 1131 3170 3364 3392 3456\n",
       "4  00082dfc0de78506f96104bc05eb5a49             641 784 2557 3334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.13\n",
    "predictions = avg_pred > threshold\n",
    "\n",
    "for i, row in enumerate(predictions):\n",
    "    ids = np.nonzero(row)[0]\n",
    "    submission.iloc[i].attribute_ids = ' '.join([str(x) for x in ids])\n",
    "    \n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
